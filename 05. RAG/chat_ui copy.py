import streamlit as st
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, FewShotChatMessagePromptTemplate
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import PromptTemplate
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model='gpt-4o') # gpt-3.5-turbo , gpt-4o
embedding = OpenAIEmbeddings(model='text-embedding-3-large')
index_name = 'lee-index'
database = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embedding)
retriever = database.as_retriever(search_kwargs={'k': 4})

system_prompt = PromptTemplate(
    template="""
    ë‹¹ì‹ ì€ ì´ì„±ê·œë¼ëŠ” ì‚¬ëŒì„ ê´‘ì ìœ¼ë¡œ ì¢‹ì•„í•˜ëŠ” ìŠ¤í† ì»¤ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. 
    ë‹¹ì‹ ì´ ê¸°ë¡í•œ ë¬¸ì„œê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í™œìš©í•´ì„œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
    ë§Œì•½ ë¬¸ì„œì—ì„œ ë‹µë³€ì„ ì•Œ ìˆ˜ ì—†ë‹¤ë©´ ë°˜ë“œì‹œ ì•Œì•„ë‚¼ ê±°ë¼ê³  ë” ìŠ¤í† í‚¹ì„ í•  ê²ƒì´ë€ ë‹µë³€í•´ì£¼ì„¸ìš”. 
    ë§Œì•½ ë¬¸ì„œì—ì„œ ë‹µë³€ì„ ì•Œ ìˆ˜ ìˆë‹¤ë©´ ë‚´ê°€ XXì¼ì— ê´€ì°°í•œ ê²°ê³¼ì— ë”°ë¥´ë©´ ì´ë¼ê³  ì‹œì‘í•˜ë©´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”. 
    ë§Œì•½ ì´ì„±ê·œì™¸ ë‹¤ë¥¸ ì‚¬ëŒì— ê´€ë ¨ëœ ì§ˆë¬¸ì´ ë“¤ì–´ì™€ë„ ê·¸ ì‚¬ëŒì€ ëª¨ë¥´ê² ê³  ì´ì„±ê·œëŠ”... ë¼ë©° ì´ì„±ê·œì— ê´€ë ¨ëœ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”. 
    2-3 ë¬¸ì¥ì •ë„ì˜ ì§§ì€ ë‚´ìš©ì˜ ë‹µë³€ì„ ì›í•©ë‹ˆë‹¤.

    {context}

    Question: {question}"""
    , input_variables=["context","question"]
)

rag_chain = system_prompt | llm

st.set_page_config(page_title="ì´ì„±ê·œ ìŠ¤í† ì»¤", page_icon="ğŸ¥·")

st.title("ğŸ¥· ì´ì„±ê·œ ìŠ¤í† ì»¤")
st.caption("ë§¤ì¼ ê´€ì°°í•œë‹¤ê³  í•˜ë„¤ìš”!")

if 'message_list' not in st.session_state:
    st.session_state.message_list = []

for message in st.session_state.message_list:
    with st.chat_message(message["role"]):
        st.write(message["content"])


if user_question := st.chat_input(placeholder="ê¶ê¸ˆí•œê²Œ ìˆìœ¼ë©´ ë¬¼ì–´ë³´ì„¸ìš”!"):
    with st.chat_message("user"):
        st.write(user_question)
    st.session_state.message_list.append({"role": "user", "content": user_question})

    with st.spinner("ğŸ•µï¸ìŠ¤í† ì»¤ê°€ ìë£Œë¥¼ ì°¾ì•„ë³´ëŠ” ì¤‘.."):
        ai_response1 = retriever.invoke(user_question)
        ai_response = rag_chain.invoke( {"context" : ai_response1,"question" : user_question})
        with st.chat_message("ai"):
            st.write(ai_response.content)
            st.session_state.message_list.append({"role": "ai", "content": ai_response.content})