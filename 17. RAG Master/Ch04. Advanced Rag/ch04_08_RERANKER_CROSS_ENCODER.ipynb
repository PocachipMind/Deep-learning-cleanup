{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cJy1t37GsyL9",
   "metadata": {
    "id": "cJy1t37GsyL9"
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain_openai langchain_community pypdf faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b57306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 먼저 구글 드라이브 마운트\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "U3aOf1kttmdQ",
   "metadata": {
    "id": "U3aOf1kttmdQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "u9eVNXBIUTsb",
   "metadata": {
    "id": "u9eVNXBIUTsb"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = (\n",
    "    \"./Data/투자설명서.pdf\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap = 100)\n",
    "\n",
    "docs = loader.load_and_split(doc_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wtwTgjcwQp1o",
   "metadata": {
    "id": "wtwTgjcwQp1o"
   },
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 데이터를 임베딩으로 변환\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p3PNlgs44qHB",
   "metadata": {
    "id": "p3PNlgs44qHB"
   },
   "outputs": [],
   "source": [
    "# FAISS 라이브러리 임포트\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터스토어 생성\n",
    "faiss_store = FAISS.from_documents(docs, embedding)\n",
    "# FAISS 벡터스토어 저장\n",
    "persist_directory = \"/content/DB\"\n",
    "faiss_store.save_local(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "urRxIxM3sUcS",
   "metadata": {
    "id": "urRxIxM3sUcS"
   },
   "outputs": [],
   "source": [
    "# 저장한 FAISS DB 불러오기\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "persist_directory = \"./DB\"\n",
    "\n",
    "vectordb = FAISS.load_local(persist_directory, embeddings=embedding, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "QO7i-mOHQ4vx",
   "metadata": {
    "id": "QO7i-mOHQ4vx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\MCP-Project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pydantic import Field\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "NkIsOHAOQ7AY",
   "metadata": {
    "id": "NkIsOHAOQ7AY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\MCP-Project\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# ms-marco-MiniLM-L-12-v2 모델 다운로드\n",
    "crossencoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sLBgdtjK6UUX",
   "metadata": {
    "id": "sLBgdtjK6UUX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23904\\3368951697.py:1: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class Retriever_with_cross_encoder(BaseRetriever):\n"
     ]
    }
   ],
   "source": [
    "class Retriever_with_cross_encoder(BaseRetriever):\n",
    "    vectorstore: Any = Field(description=\"초기 검색을 위한 벡터 저장소\")\n",
    "    crossencoder: Any = Field(description=\"재순위화를 위한 크로스 인코더 모델\")\n",
    "    k: int = Field(default=5, description=\"초기에 검색할 문서 수\")\n",
    "    rerank_top_k: int = Field(default=2, description=\"재순위화 후 최종적으로 반환할 문서 수\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # 초기 검색\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
    "\n",
    "        # 인코더용 쌍 준비\n",
    "        pairs = [[query, doc.page_content] for doc in initial_docs]\n",
    "\n",
    "        # 인코더 점수 획득\n",
    "        scores = self.crossencoder.predict(pairs)\n",
    "\n",
    "        # 점수별 문서 정렬\n",
    "        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 상위 재순위화 문서 반환\n",
    "        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "GQgtEgOLRtwJ",
   "metadata": {
    "id": "GQgtEgOLRtwJ"
   },
   "outputs": [],
   "source": [
    "# 크로스인코더 기반 리트리버 인스턴스 생성\n",
    "cross_encoder_retriever = Retriever_with_cross_encoder(\n",
    "    vectorstore=vectordb,\n",
    "    crossencoder=crossencoder,\n",
    "    k=4,  # 초기 밀집검색으로 반환할 문서 수를 설정\n",
    "    rerank_top_k=2  # 리랭킹을 통해 최종적으로 반환할 문서 수를 설정\n",
    ")\n",
    "\n",
    "# 답변용 LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "XRsXe5Q47eft",
   "metadata": {
    "id": "XRsXe5Q47eft"
   },
   "outputs": [],
   "source": [
    "# RetrievalQA 체인 인스턴스 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=cross_encoder_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "GtjlHUxKIOm4",
   "metadata": {
    "id": "GtjlHUxKIOm4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23904\\802996342.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 이 회사의 2022년 영업손실이 정확히 얼마야?\n",
      "답변: 이 회사의 2022년 영업손실은 149.1억원입니다.\n",
      "\n",
      "답변 근거 문서:\n",
      "\n",
      "Document 1:\n",
      "이어, 당사는 2022년 GMP시설의 위탁생산계약 매출 약 4.8억원이 발생하였으나, 종업원급\n",
      "여 43.9억원, 유무형자산상각비 25.3억원이 발생하였으며, 연구개발 및 임상시험 지속 과정\n",
      "에서 지급수수료가 54.8억원 발생하는 등 총 영업비용 154억원이 발생하였습니다. 이에\n",
      "2022년 영업손실 149억원이 발생하였으며, 한편, 2022년 5월 금융감독원에서 공표한 '전환\n",
      "사채 콜옵션 회계처리' 감독지침에 따라 당사는 2021년 3월 19일 발행한 제2회 전환사채의\n",
      "\n",
      "Document 2:\n",
      "하여 2021년 영업손실 130.1억원, 2022년 영업손실 149.1억원, 2023년 영업손실 122억원, 2024년\n",
      "1분기 영업손실 24.2억원이 발생하였습니다. 또한 영업 외적 측면에서도, 금융비용 등의 발생 영향\n",
      "으로 인해 2021년 당기순손실 130.7억원, 2022년 당기순손실 228.7억원, 2023년 당기순손실\n",
      "116.1억원, 2024년 1분기 당기순손실 32.9억원이 발생하는 등 지속적인 적자 구조를 면하지 못하고\n",
      "있습니다.따라서 당사의 파이프라인에서 임상 성공을 통한 기술이전, 상품화 성공 등의 성과를 이루\n"
     ]
    }
   ],
   "source": [
    "query = \"이 회사의 2022년 영업손실이 정확히 얼마야?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\n질문: {query}\")\n",
    "print(f\"답변: {result['result']}\")\n",
    "print(\"\\n답변 근거 문서:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content)  # Print each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb510eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
